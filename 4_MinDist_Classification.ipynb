{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd428087",
   "metadata": {},
   "source": [
    "# Minimum Distance Classification of Telugu Vowel Dataset\n",
    "### It has 6 classes and 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2db9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            row = list(map(int, line.strip().split()))\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "data = read_data(r\"D:\\1st_Year_QMS\\2nd_Sem\\PR\\Vowel_Data_Only.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aeb22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.8):\n",
    "    np.random.shuffle(data)\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for label in range(1, 7):  # Assuming class labels start from 1\n",
    "        class_data = [row for row in data if row[0] == label]\n",
    "        num_train = int(train_ratio * len(class_data))\n",
    "        train_data.extend(class_data[:num_train])\n",
    "        test_data.extend(class_data[num_train:])\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b6250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([ 607.01754386, 1457.89473684, 2375.61403509]),\n",
       " 2: array([ 704.92957746, 1241.54929577, 2340.84507042]),\n",
       " 3: array([ 340.58394161, 2200.72992701, 2805.40145985]),\n",
       " 4: array([ 357.33333333,  968.33333333, 2498.66666667]),\n",
       " 5: array([ 504.84848485, 1843.21212121, 2612.06060606]),\n",
       " 6: array([ 485.76388889, 1060.48611111, 2503.26388889])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_centroids(data):\n",
    "    centroids = {}\n",
    "    for label in range(1, 7):\n",
    "        class_data = np.array([row[1:] for row in data if row[0] == label])\n",
    "        class_centroid = np.mean(class_data, axis=0)\n",
    "        centroids[label] = class_centroid\n",
    "    return centroids\n",
    "\n",
    "class_centroids = calculate_centroids(train_data)\n",
    "class_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f544c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def minimum_distance_classifier(x, centroids):\n",
    "    min_distance = float('inf')\n",
    "    min_label = None\n",
    "    for label, centroid in centroids.items():\n",
    "        distance = euclidean_distance(x, centroid)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_label = label\n",
    "    return min_label\n",
    "\n",
    "def classify_data(data, centroids):\n",
    "    classified_data = []\n",
    "    for row in data:\n",
    "        x = row[1:]\n",
    "        label = minimum_distance_classifier(x, centroids)\n",
    "        classified_data.append([label] + x)\n",
    "    return classified_data\n",
    "\n",
    "classified_test_data = classify_data(test_data, class_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39af2079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6779661016949152\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(test_data, classified_data):\n",
    "    correct = sum(1 for true, classified in zip(test_data, classified_data) if true[0] == classified[0])\n",
    "    total = len(test_data)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(test_data, classified_test_data)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e678b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_to_excel(test_data, classified_data, accuracy, output_file):\n",
    "    test_df = pd.DataFrame(test_data, columns=[\"Actual y\", \"x1\", \"x2\", \"x3\"])\n",
    "    classified_df = pd.DataFrame(classified_data, columns=[\"Classified y\", \"x1\", \"x2\", \"x3\"])\n",
    "    accuracy_df = pd.DataFrame({\"Accuracy\": [accuracy]})\n",
    "    \n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        combined_df = pd.concat([test_df, classified_df], axis=1)\n",
    "        combined_df.to_excel(writer, sheet_name=\"Classified vs Actual Data\", index=False)\n",
    "        accuracy_df.to_excel(writer, sheet_name=\"Accuracy Results\", index=False)\n",
    "\n",
    "save_path = r\"D:\\1st_Year_QMS\\2nd_Sem\\PR\\classification_results_min_distance.xlsx\"\n",
    "save_to_excel(test_data, classified_test_data, accuracy, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa6ddb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 80.0% training set, accuracy = 0.7147\n",
      "At 70.0% training set, accuracy = 0.7087\n",
      "At 60.0% training set, accuracy = 0.692\n"
     ]
    }
   ],
   "source": [
    "split_list = [0.8, 0.7, 0.6]\n",
    "\n",
    "for i in split_list:\n",
    "    tot_acc=0\n",
    "    runs = 10\n",
    "    for j in range(runs):\n",
    "        train_data, test_data = split_data(data, train_ratio=i)\n",
    "        class_centroids = calculate_centroids(train_data)\n",
    "        classified_test_data = classify_data(test_data, class_centroids)\n",
    "        accuracy = calculate_accuracy(test_data, classified_test_data)\n",
    "        tot_acc+=accuracy  # Adding accuracies found in each run to get the average.\n",
    "    avg_acc = tot_acc/runs\n",
    "    print(f\"At {100*i}% training set, accuracy = {round(avg_acc, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
