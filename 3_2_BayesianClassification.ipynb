{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce17f66",
   "metadata": {},
   "source": [
    "# Bayesian Classification on Telugu Vowel Dataset\n",
    "### It has 6 classes and 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ed0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            row = list(map(int, line.strip().split()))\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "data = read_data(r\"D:\\1st_Year_QMS\\2nd_Sem\\PR\\Vowel_Data_Only.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422d31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.8):\n",
    "    np.random.shuffle(data)\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for label in range(1, 7):  # Assuming class labels start from 1\n",
    "        class_data = [row for row in data if row[0] == label]\n",
    "        num_train = int(train_ratio * len(class_data))\n",
    "        train_data.extend(class_data[:num_train])\n",
    "        test_data.extend(class_data[num_train:])\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b81d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (array([ 603.50877193, 1453.50877193, 2354.21052632]),\n",
       "  array([ 6128.03939674, 35163.12711604, 26620.86795937])),\n",
       " 2: (array([ 697.88732394, 1239.43661972, 2338.73239437]),\n",
       "  array([ 3551.87462805, 11543.34457449, 27196.98472525])),\n",
       " 3: (array([ 344.52554745, 2198.54014599, 2806.78832117]),\n",
       "  array([ 3163.46102616, 31567.21189195, 45677.27635996])),\n",
       " 4: (array([ 359.58333333,  979.16666667, 2485.83333333]),\n",
       "  array([ 2095.65972222, 14190.97222222, 34065.97222222])),\n",
       " 5: (array([ 502.72727273, 1868.66666667, 2621.45454545]),\n",
       "  array([ 6462.25895317, 80587.31313131, 37302.12672176])),\n",
       " 6: (array([ 478.81944444, 1049.72222222, 2501.18055556]),\n",
       "  array([ 3249.30073302, 12497.14506173, 47936.80073302]))}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_statistics(data):\n",
    "    stats = {}\n",
    "    for label in range(1, 7):\n",
    "        class_data = np.array([row[1:] for row in data if row[0] == label])\n",
    "        class_mean = np.mean(class_data, axis=0)\n",
    "        class_variance = np.var(class_data, axis=0)\n",
    "        stats[label] = (class_mean, class_variance)\n",
    "    return stats\n",
    "\n",
    "class_stats = calculate_statistics(train_data)\n",
    "class_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c585eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_probability(x, mean, variance):\n",
    "    exponent = np.exp(-((x - mean) ** 2) / (2 * variance))\n",
    "    return (1 / np.sqrt(2 * np.pi * variance)) * exponent\n",
    "\n",
    "def bayesian_classifier(x, class_stats):\n",
    "    probabilities = {}\n",
    "    for label, (class_mean, class_variance) in class_stats.items():\n",
    "        probabilities[label] = np.prod(gaussian_probability(x, class_mean, class_variance))\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "def classify_data(data, class_stats):\n",
    "    classified_data = []\n",
    "    for row in data:\n",
    "        x = row[1:]\n",
    "        label = bayesian_classifier(x, class_stats)\n",
    "        classified_data.append([label] + x)\n",
    "    return classified_data\n",
    "\n",
    "classified_test_data = classify_data(test_data, class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7641595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8361581920903954\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(test_data, classified_data):\n",
    "    correct = sum(1 for true, classified in zip(test_data, classified_data) if true[0] == classified[0])\n",
    "    total = len(test_data)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(test_data, classified_test_data)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2aef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def save_to_excel(test_data, classified_data, accuracy, output_file):\n",
    "    test_df = pd.DataFrame(test_data, columns=[\"Actual y\", \"x1\", \"x2\", \"x3\"])\n",
    "    classified_df = pd.DataFrame(classified_data, columns=[\"Classified y\", \"x1\", \"x2\", \"x3\"])\n",
    "    accuracy_df = pd.DataFrame({\"Accuracy\": [accuracy]})\n",
    "    \n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        combined_df = pd.concat([test_df, classified_df], axis=1)\n",
    "        combined_df.to_excel(writer, sheet_name=\"Classified vs Actual Data\", index=False)\n",
    "        accuracy_df.to_excel(writer, sheet_name=\"Accuracy Results\", index=False)\n",
    "\n",
    "save_path = r\"D:\\1st_Year_QMS\\2nd_Sem\\PR\\classification_results_bayesian.xlsx\"\n",
    "save_to_excel(test_data, classified_test_data, accuracy, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef2ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 80.0% training set, accuracy = 0.7644\n",
      "At 70.0% training set, accuracy = 0.7992\n",
      "At 60.0% training set, accuracy = 0.786\n"
     ]
    }
   ],
   "source": [
    "split_list = [0.8, 0.7, 0.6]\n",
    "for i in split_list:\n",
    "    tot_acc=0\n",
    "    runs = 10\n",
    "    for j in range(runs):\n",
    "        train_data, test_data = split_data(data, train_ratio = i)\n",
    "        class_stats = calculate_statistics(train_data)\n",
    "        #    class_stats\n",
    "        classified_test_data = classify_data(test_data, class_stats)\n",
    "        #    classified_test_data\n",
    "        accuracy = calculate_accuracy(test_data, classified_test_data)\n",
    "        tot_acc+=accuracy  # Adding accuracies found in each run to get the average.\n",
    "    avg_acc = tot_acc/runs\n",
    "    print(f\"At {100*i}% training set, accuracy = {round(avg_acc, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
